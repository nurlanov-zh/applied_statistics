{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.lm as lm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from nltk.util import ngrams as nltk_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = u'SOS SOS '+u'А Б '*100+'EOS'\n",
    "tokens = text.split()\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "prefix = []\n",
    "\n",
    "n = len(tokens)\n",
    "for i in range(3):\n",
    "    ngrams.append(Counter([tuple(tokens[j:j+i+1]) for j in range(n-i)]))\n",
    "    prefix.append(Counter([tuple(tokens[j:j+i]+['*']) for j in range(n-i)]))\n",
    "    \n",
    "ngrams, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {}\n",
    "for w in ngrams[0]:\n",
    "    p1[w] = ngrams[0][w]/n\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = {}\n",
    "for w in ngrams[1]:\n",
    "    pre_w = tuple([w[0]]+['*']*1)       \n",
    "    p2[u'{1}|{0}'.format(*w)] = ngrams[1][w]/prefix[1][pre_w]\n",
    "   \n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = {}\n",
    "for w in ngrams[2]:\n",
    "    pre_w = w[:2]+tuple('*')\n",
    "    p3[u'{2}|{1},{0}'.format(*w)] = ngrams[2][w]/prefix[2][pre_w]\n",
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat2 = []\n",
    "stat3 = []\n",
    "m = len(p3)\n",
    "for i in range(n-2):\n",
    "    w = tokens[i:i+3]\n",
    "    ngram3 = u'{2}|{1},{0}'.format(*w)\n",
    "    ngram2 = u'{1}|{0}'.format(*w)\n",
    "    \n",
    "    stat2.append(np.log(p2[ngram2]))\n",
    "    stat3.append(np.log(p3[ngram3]))\n",
    "stat = -2*np.sum(stat2)-2*np.sum(stat3)\n",
    "\n",
    "1-st.distributions.chi2(m*((m-1)**2)-1).cdf(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = u'SOS SOS '+u'А Б Б А Б А Б А Б Б А А '*100\n",
    "tokens = text.split()\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "prefix = []\n",
    "\n",
    "n = len(tokens)\n",
    "for i in range(3):\n",
    "    ngrams.append(Counter([tuple(tokens[j:j+i+1]) for j in range(n-i)]))\n",
    "    prefix.append(Counter([tuple(tokens[j:j+i]+['*']) for j in range(n-i)]))\n",
    "    \n",
    "ngrams, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = {}\n",
    "for w in ngrams[0]:\n",
    "    p1[w] = ngrams[0][w]/n\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = {}\n",
    "for w in ngrams[1]:\n",
    "    pre_w = tuple([w[0]]+['*']*1)       \n",
    "    p2[u'{1}|{0}'.format(*w)] = ngrams[1][w]/prefix[1][pre_w]\n",
    "   \n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = {}\n",
    "for w in ngrams[2]:\n",
    "    pre_w = w[:2]+tuple('*')\n",
    "    p3[u'{2}|{1},{0}'.format(*w)] = ngrams[2][w]/prefix[2][pre_w]\n",
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat2 = []\n",
    "stat3 = []\n",
    "\n",
    "for i in range(n-2):\n",
    "    w = tokens[i:i+3]\n",
    "    ngram3 = u'{2}|{1},{0}'.format(*w)\n",
    "    ngram2 = u'{1}|{0}'.format(*w)\n",
    "    \n",
    "    stat2.append(np.log(p2[ngram2]))\n",
    "    stat3.append(np.log(p3[ngram3]))\n",
    "stat = -2*np.sum(stat2)-2*np.sum(stat3)\n",
    "1-st.distributions.chi2(m*((m-1)**2)-1).cdf(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = lm.Laplace(order=3)\n",
    "n1 = nltk_ngrams(tokens, 1)\n",
    "n2 = nltk_ngrams(tokens, 2)\n",
    "n3 = nltk_ngrams(tokens, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.fit([list(n1)]+[list(n2)]+[list(n3)],vocabulary_text=list(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.perplexity(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.logscore('A', context=['SOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.logscore('SOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.logscore('EOS', context=['B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.logscore('EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.logscore('WW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Вот дом,\n",
    "Который построил Джек.\n",
    "\n",
    "А это пшеница,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "А это весёлая птица-синица,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "Вот кот,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "Вот пёс без хвоста,\n",
    "Который за шиворот треплет кота,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "А это корова безрогая,\n",
    "Лягнувшая старого пса без хвоста,\n",
    "Который за шиворот треплет кота,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "А это старушка, седая и строгая,\n",
    "Которая доит корову безрогую,\n",
    "Лягнувшую старого пса без хвоста,\n",
    "Который за шиворот треплет кота,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "А это ленивый и толстый пастух,\n",
    "Который бранится с коровницей строгою,\n",
    "Которая доит корову безрогую,\n",
    "Лягнувшую старого пса без хвоста,\n",
    "Который за шиворот треплет кота,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\n",
    "Вот два петуха,\n",
    "Которые будят того пастуха,\n",
    "Который бранится с коровницей строгою,\n",
    "Которая доит корову безрогую,\n",
    "Лягнувшую старого пса без хвоста,\n",
    "Который за шиворот треплет кота,\n",
    "Который пугает и ловит синицу,\n",
    "Которая часто ворует пшеницу,\n",
    "Которая в тёмном чулане хранится\n",
    "В доме,\n",
    "Который построил Джек.\n",
    "\"\"\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "rt = RegexpTokenizer(u'\\w+')\n",
    "vocab = set()\n",
    "tokens = rt.tokenize(text)\n",
    "\n",
    "\n",
    "len(tokens), len(set(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = nltk_ngrams(tokens, 1) \n",
    "n2 = nltk_ngrams(tokens, 2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = lm.Laplace(order=3)\n",
    "laplace.fit([list(n1)]+[list(n2)]+[list(n3)],vocabulary_text=list(set(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u' '.join(laplace.generate(150, random_seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u' '.join(laplace.generate(150, text_seed=u'вот дом который построил джек'.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
