{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 8\n",
    "\n",
    "Даны результаты работы трех машинных переводчиков (N,P,Z) на небольших выборках переводов с английского на немецкий, с английского на русский и с казахского на русский\n",
    "\n",
    "Требуется определить для каких пар языков можно выделить какого-либо лидера среди переводчиков. Для BLEU учитывать только слова, регистр не учитывать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate import bleu_score as score \n",
    "import re\n",
    "import string\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from statsmodels.stats.descriptivestats import sign_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем коллекцию документов как словарь\n",
    "collection[название документа] = текст документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_collection(path):\n",
    "    collection = dict()\n",
    "    for file_name in os.listdir(path):\n",
    "        with open(path + '/' + file_name, 'r') as f_input:\n",
    "            new_document = f_input.read()\n",
    "            collection[file_name.strip(\".txt\")] = new_document\n",
    "    return collection\n",
    "\n",
    "collection = load_collection(\"./mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['en_ru_n', 'en_de_n', 'kk_ru_orig', 'en_ru_z.txt~', 'kk_ru_n', 'kk_ru_gold', 'kk_ru_p', 'en_ru_gold', 'en_ru_p', 'en_ru_z', 'en_de_p', 'en_de_z', 'en_de_gold', 'en_ru_orig', 'kk_ru_z', 'en_de_orig'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка коллекции:\n",
    " - Текст бьется на предложения\n",
    " - Внутри предложения:\n",
    "  - Слова приводятся к нижнему регистру\n",
    "  - Убираются знаки препинания и цифры\n",
    "  - Проводится токенезация\n",
    " \n",
    "В результате получается, что каждый текст - список предложений, каждое предложение - список токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    new_text = []\n",
    "    sentences = text.split(\"\\n\")\n",
    "    for i, sent in enumerate(sentences):\n",
    "        if len(sent) > 0:\n",
    "            sent = re.sub(r\"[\"+ string.punctuation + \"1234567890\" + \"]\",  ' ', sent)\n",
    "            sent = sent.lower()\n",
    "            sent = re.sub(' +', ' ', sent)\n",
    "            new_text.append(sent.strip().split(\" \"))\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем новый словарь с предобработанной коллекцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_collection = dict()\n",
    "for key in collection.keys():\n",
    "    prepared_collection[key]= text_prepare(collection[key])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, которая для конкретной пары языков считает sentence_bleu_score для каждых трех переводчиков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(lang_pair):\n",
    "    score_n = []\n",
    "    for i in range(len(prepared_collection[lang_pair + \"_gold\"])):\n",
    "        score_n.append(sentence_bleu([prepared_collection[lang_pair + \"_gold\"][i]], \\\n",
    "                                   prepared_collection[lang_pair + \"_n\"][i],\\\n",
    "                                   smoothing_function = score.SmoothingFunction().method3))#, weights=(0.5, 0.25, 0.25)))\n",
    "    score_z = []\n",
    "    for i in range(len(prepared_collection[lang_pair + \"_gold\"])):\n",
    "        score_z.append(sentence_bleu([prepared_collection[lang_pair + \"_gold\"][i]], \\\n",
    "                                   prepared_collection[lang_pair + \"_z\"][i],\\\n",
    "                                   smoothing_function = score.SmoothingFunction().method3))#, weights=(0.5, 0.25, 0.25)))\n",
    "\n",
    "    score_p = []\n",
    "    for i in range(len(prepared_collection[lang_pair + \"_gold\"])):\n",
    "        score_p.append(sentence_bleu([prepared_collection[lang_pair + \"_gold\"][i]], \\\n",
    "                                   prepared_collection[lang_pair + \"_p\"][i], \n",
    "                                   smoothing_function = score.SmoothingFunction().method3))#, weights=(0.5, 0.25, 0.25)))\n",
    "    return np.array(score_n), np.array(score_z), np.array(score_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка одиночной гипотезы\n",
    "Мы видим, что выборки связанные и малеькие по размеру. \n",
    "Поэтому чтобы проверить одиночную гипотезу о среднем, мы можем использовать все те же критерии, что и в первом задании: Критерий знаков, перестановок, Уилкоксона и t-test, если Шапиро не отклоняет гипотезу о нормальности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что говорит нам критерий Шапиро о применимости t-testa:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Язык en-ru:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_n, scor_z, score_p = calculate_score(\"en_ru\")\n",
    "print(st.shapiro(score_n))\n",
    "print(st.shapiro(score_z))\n",
    "print(st.shapiro(score_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Язык en_de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7521209716796875, 0.0037873859982937574)\n",
      "(0.6457548141479492, 0.00019513994629960507)\n",
      "(0.748779833316803, 0.003448653733357787)\n"
     ]
    }
   ],
   "source": [
    "score_n, scor_z, score_p = calculate_score(\"en_de\")\n",
    "print(st.shapiro(score_n))\n",
    "print(st.shapiro(score_z))\n",
    "print(st.shapiro(score_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "язык kk_ru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6598911285400391, 0.00028866127831861377)\n",
      "(0.6457548141479492, 0.00019513994629960507)\n",
      "(0.8266522884368896, 0.030492015182971954)\n"
     ]
    }
   ],
   "source": [
    "score_n, scor_z, score_p = calculate_score(\"kk_ru\")\n",
    "print(st.shapiro(score_n))\n",
    "print(st.shapiro(score_z))\n",
    "print(st.shapiro(score_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод: так как в большинстве случаев shapiro сильно отвергается, использовать ttest не будем\n",
    "#### Кроме того, в текстах всего по 10 предложений - этого мало, чтобы проводить в Уилкоксоне нормальную аппроксимацию. Стандартную функцию не используем, используем свою функцию без аппроксимации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дизайн эксперимента №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формулируем гипотезы:\n",
    "Каждый тест мы разбиваем на предложения. Для каждого предложения считаем bleu_score. \n",
    "После этого для каждой пары языков и для каждого переводчика у нас появилась выборка $x_1, ..., x_n$ - blue_score предложений как оценка качества перевода. Для каждой пары языков и для каждого переводчика проводим множественное тестирование гипотез:\n",
    " - $H_{0_{Np}}: m_n = m_p$\n",
    " \n",
    "   $H_{1_{Np}}: m_n < m_p$\n",
    "   \n",
    "и\n",
    "   \n",
    " - $H_{0_{Nz}}: m_n = m_z$\n",
    " \n",
    "   $H_{1_{Nz}}: m_n < m_z$ \n",
    "   \n",
    "Если мы отвергли обе вышенаписанные гипотезы, мы можем сказать, что, например, N является лидером перевода для какой-то пары языков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Множественное тестирование\n",
    "Для множественного тестирования используем поправку Бенджамини — Хохберга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция проводит множественное тестирование с поправкой Бенджамини — Хохберга на уровне  $\\alpha$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Benjamini(leader, data1, data2, test, alpha, data_list):\n",
    "    #data is shape set_number x set_size\n",
    "    test_result = []\n",
    "    if test.__name__ == 'permute_test':\n",
    "        p_1 = tuple(test(leader, data1, \"greater\"))[1]\n",
    "        p_2 = tuple(test(leader, data2, \"greater\"))[1]\n",
    "    elif test.__name__ == \"ttest_rel\" :\n",
    "        if st.shapiro(data1)[1] < alpha or st.shapiro(data2)[1] < alpha or st.shapiro(leader)[1] < alpha:\n",
    "            print(\"Can't perform t-test\")\n",
    "            return 0\n",
    "    else:\n",
    "        p_1 = tuple(test(leader, data1))[1] \n",
    "        p_2 = tuple(test(leader, data2))[1]\n",
    "\n",
    "    less, great = sorted([p_1, p_2])\n",
    "    \n",
    "    if less >= alpha/2:\n",
    "        print(\"Can't reject both hypotheses, for [\", data_list[0], \",\", data_list[1], \"] - \", p_1,\\\n",
    "                                             \"for [\", data_list[0], \",\", data_list[2], \"] - \", p_2)\n",
    "    elif great >= alpha:\n",
    "        print(\"One hypothesis rejected, for [\", data_list[0], \",\", data_list[1], \"] - \", p_1,\\\n",
    "                                             \"for [\", data_list[0], \",\", data_list[2], \"] - \", p_2)\n",
    "    else:\n",
    "        print(\"Both hypotheses rejected, for [\", data_list[0], \",\", data_list[1], \"] - \", p_1,\\\n",
    "                                             \"for [\", data_list[0], \",\", data_list[2], \"] - \", p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_test(data1, data2, alternative):\n",
    "    D = data1 - data2\n",
    "    t = np.sum(D)\n",
    "    good = 0\n",
    "    count = 0\n",
    "    for v in list(itertools.product([-1, 1], repeat=data1.shape[0])):\n",
    "        count +=1\n",
    "        stat = np.array(v).T.dot(D)\n",
    "        if alternative == \"greater\":\n",
    "            if stat >= t:\n",
    "                good+=1\n",
    "        elif alternative == \"lower\":\n",
    "            if stat <= t:\n",
    "                good+=1\n",
    "        elif alternative == \"two-side\":\n",
    "            if abs(stat) >= abs(t):\n",
    "                good+=1\n",
    "        else:\n",
    "            return Nan, Nan\n",
    "    return t, good/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon(data1, data2):\n",
    "    rank = st.rankdata(np.abs(data1 - data2))\n",
    "    sign = np.sign(data1 - data2)\n",
    "    t = np.sum(rank*sign)\n",
    "    good = 0\n",
    "    count = 0\n",
    "    for v in list(itertools.product([-1, 1], repeat=data1.shape[0])):\n",
    "        count +=1\n",
    "        stat = np.array(v).T.dot(rank)\n",
    "        if abs(stat) >= abs(t):\n",
    "            good +=1\n",
    "    return t, good/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitest(lang):\n",
    "    #data has sahape num_translators x num_sentences\n",
    "    score_n, score_z, score_p = calculate_score(lang)\n",
    "    data = np.array([score_n, score_z, score_p])\n",
    "    print(\"Lang is \" + lang, \">>>\")\n",
    "    test_list = [wilcoxon, sign_test, permute_test ]\n",
    "    for i in range(data.shape[0]):\n",
    "        print(\"Testing leader is\", i, \">>\")\n",
    "        for test in test_list:\n",
    "            print(test.__name__)\n",
    "            calculate_Benjamini(data[i], data[i - 1], data[i - 2], test, 0.05, [i, (i - 1)%3, (i - 2)%3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем пару языков \"en_ru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang is en_ru >>>\n",
      "Testing leader is 0 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.431640625 for [ 0 , 1 ] -  0.322265625\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.5078125 for [ 0 , 1 ] -  0.7539062500000002\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.8359375 for [ 0 , 1 ] -  0.115234375\n",
      "Testing leader is 1 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.322265625 for [ 1 , 2 ] -  0.193359375\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.7539062500000002 for [ 1 , 2 ] -  0.7539062500000002\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.884765625 for [ 1 , 2 ] -  0.9423828125\n",
      "Testing leader is 2 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.193359375 for [ 2 , 0 ] -  0.431640625\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.7539062500000002 for [ 2 , 0 ] -  0.5078125\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.0576171875 for [ 2 , 0 ] -  0.1640625\n"
     ]
    }
   ],
   "source": [
    "multitest(\"en_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ничего не можем отклонить - нет лидера для  en_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пара языков kk_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang is kk_ru >>>\n",
      "Testing leader is 0 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.625 for [ 0 , 1 ] -  0.921875\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.5078125 for [ 0 , 1 ] -  0.5078125\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.5625 for [ 0 , 1 ] -  0.779296875\n",
      "Testing leader is 1 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.921875 for [ 1 , 2 ] -  0.322265625\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.5078125 for [ 1 , 2 ] -  0.5078125\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.22265625 for [ 1 , 2 ] -  0.126953125\n",
      "Testing leader is 2 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.322265625 for [ 2 , 0 ] -  0.625\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.5078125 for [ 2 , 0 ] -  0.5078125\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.875 for [ 2 , 0 ] -  0.4375\n"
     ]
    }
   ],
   "source": [
    "multitest(\"kk_ru\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ничего не можем отклонить - нет лидера для  kk_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пара языков en_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang is en_de >>>\n",
      "Testing leader is 0 >>\n",
      "wilcoxon\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.76953125 for [ 0 , 1 ] -  0.048828125\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 0 , 2 ] -  0.7539062500000002 for [ 0 , 1 ] -  0.10937500000000003\n",
      "permute_test\n",
      "One hypothesis rejected, for [ 0 , 2 ] -  0.4638671875 for [ 0 , 1 ] -  0.01953125\n",
      "Testing leader is 1 >>\n",
      "wilcoxon\n",
      "Both hypotheses rejected, for [ 1 , 0 ] -  0.048828125 for [ 1 , 2 ] -  0.013671875\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.10937500000000003 for [ 1 , 2 ] -  0.10937500000000003\n",
      "permute_test\n",
      "Can't reject both hypotheses, for [ 1 , 0 ] -  0.98046875 for [ 1 , 2 ] -  0.994140625\n",
      "Testing leader is 2 >>\n",
      "wilcoxon\n",
      "One hypothesis rejected, for [ 2 , 1 ] -  0.013671875 for [ 2 , 0 ] -  0.76953125\n",
      "sign_test\n",
      "Can't reject both hypotheses, for [ 2 , 1 ] -  0.10937500000000003 for [ 2 , 0 ] -  0.7539062500000002\n",
      "permute_test\n",
      "One hypothesis rejected, for [ 2 , 1 ] -  0.005859375 for [ 2 , 0 ] -  0.5361328125\n"
     ]
    }
   ],
   "source": [
    "multitest(\"en_de\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что permute_test с односторонней альтернативой отвергает по одной гипотезе в эксперименте \"лидер - это 0(n)\" и \"лидер - это 2(p)\", а Уилкоксон с двусторонней альтернативой отвергает обе гипотезы для \"лидер - это 1(z)\"\n",
    "#### Значит, для en_de мы нашли не лидера, а аутсайдера (это z), а про p, n мы ничего сказать не можем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Другой дизайн эксперимента\n",
    "Теперь мы тестируем гипотезу о равенстве средних для всех упорядоченных пар(если проверяем одностороннюю альтернативу) или для всех неупорядоченных пар(если проверяем двухстороннюю альтернативу) с поправкой Бенджамини для всего множества получившихся пар."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Benjamini(data, test, alpha, is_one_sided=False):\n",
    "    #data is shape set_number x set_size\n",
    "    set_len = data.shape[0]\n",
    "    p_val_list = []\n",
    "    if is_one_sided:\n",
    "        for i in range(set_len):\n",
    "            for j in range(set_len):\n",
    "                if i != j:\n",
    "                    _, p_val = test(data[i], data[j], \"greater\")\n",
    "                    p_val_list.append([p_val, [i , j]])\n",
    "    else:\n",
    "        for i in range(set_len - 1):\n",
    "            for j in range(i + 1, set_len):\n",
    "                _, p_val = test(data[i], data[j])\n",
    "                p_val_list.append([p_val, [i , j]])\n",
    "    p_val_list = sorted(p_val_list, key= lambda x: x[0])\n",
    "    m = len(p_val_list)\n",
    "    for i in range(m):\n",
    "        if p_val_list[i][0] > alpha/(m - i):\n",
    "            print(\"hypotheses from\", i ,\"accepted\")\n",
    "            break\n",
    "    return p_val_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем пару en_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(calculate_score(\"en_ru\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0576171875, [2, 1]],\n",
       " [0.115234375, [0, 1]],\n",
       " [0.1640625, [2, 0]],\n",
       " [0.8359375, [0, 2]],\n",
       " [0.884765625, [1, 0]],\n",
       " [0.9423828125, [1, 2]]]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, permute_test, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5078125, [0, 2]],\n",
       " [0.7539062500000002, [0, 1]],\n",
       " [0.7539062500000002, [1, 2]]]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, sign_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.193359375, [1, 2]], [0.322265625, [0, 1]], [0.431640625, [0, 2]]]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, wilcoxon, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ничего не можем отклонить - нет лидера для en_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем пару en_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 1 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.005859375, [2, 1]],\n",
       " [0.01953125, [0, 1]],\n",
       " [0.4638671875, [0, 2]],\n",
       " [0.5361328125, [2, 0]],\n",
       " [0.98046875, [1, 0]],\n",
       " [0.994140625, [1, 2]]]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(calculate_score(\"en_de\"))\n",
    "## (n = 0, z = 1, p = 2)\n",
    "calculate_Benjamini(data, permute_test, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 1 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.013671875, [1, 2]], [0.048828125, [0, 1]], [0.76953125, [0, 2]]]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, wilcoxon, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.10937500000000003, [0, 1]],\n",
       " [0.10937500000000003, [1, 2]],\n",
       " [0.7539062500000002, [0, 2]]]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, sign_test, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oтклоняем гипотезу [1, 2]  - то есть среднее p больше, чем среднее z. Однако, гипотеза о том, что p лучше n (гипотеза [2, 0]) не отвергается даже без поправки. Значит, лидер кто-то из p и n, а z - аутсайдер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем пару kk_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.126953125, [1, 2]],\n",
       " [0.22265625, [1, 0]],\n",
       " [0.4375, [2, 0]],\n",
       " [0.5625, [0, 2]],\n",
       " [0.779296875, [0, 1]],\n",
       " [0.875, [2, 1]]]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(calculate_score(\"kk_ru\"))\n",
    "calculate_Benjamini(data, permute_test, 0.05, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.5078125, [0, 1]], [0.5078125, [0, 2]], [0.5078125, [1, 2]]]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, sign_test, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypotheses from 0 accepted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.322265625, [1, 2]], [0.625, [0, 2]], [0.921875, [0, 1]]]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_Benjamini(data, wilcoxon, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ничего не можем отклонить - нет лидера для kk_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: мы ничего не можем сказать о лидерах. Для пары языков \"en_de\" нашли аутсайдера z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
